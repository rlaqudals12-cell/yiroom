# API Rate Limiting 완벽 가이드: Yiroom 서비스를 위한 구현 전략

**서버리스 환경에서 가장 효과적인 Rate Limiting 솔루션은 Upstash Redis + Sliding Window Counter 알고리즘의 조합입니다.** 이 구성은 Cloudflare가 하루 수십억 건의 요청을 처리하며 검증했고, 메모리 효율성(사용자당 ~24바이트)과 정확도(99.997%)의 최적 균형을 제공합니다. Yiroom의 Next.js 16 + Vercel + Supabase 스택에서는 미들웨어 레벨의 @upstash/ratelimit 패키지를 활용하여 엔드포인트별 차등 제한을 구현하고, AI 이미지 분석 엔드포인트에는 큐 기반 처리를 적용하는 것이 최적의 아키텍처입니다.

---

## Rate Limiting 알고리즘 비교 분석

Rate Limiting의 핵심은 적절한 알고리즘 선택입니다. 각 알고리즘은 메모리 사용량, 정확도, 버스트 허용 여부에서 뚜렷한 차이를 보이며, 서버리스/엣지 환경에서의 적합성도 크게 달라집니다.

### 알고리즘별 상세 비교표

| 알고리즘 | 메모리 (사용자당) | 시간복잡도 | 정확도 | 버스트 허용 | 서버리스 적합성 |
|---------|-----------------|-----------|--------|------------|---------------|
| **Fixed Window** | 8-16 bytes | O(1) | 낮음 (경계 문제) | 제한적 | ⭐⭐⭐ |
| **Sliding Window Counter** | ~24 bytes | O(1) | 매우 높음 (99.997%) | 중간 | ⭐⭐⭐⭐⭐ |
| **Sliding Window Log** | ~8KB+ (1K req/min 기준) | O(n) | 완벽 (100%) | 중간 | ⭐ |
| **Token Bucket** | ~16 bytes | O(1) | 높음 | **최고** | ⭐⭐⭐⭐ |
| **Leaky Bucket** | ~16 bytes | O(1) | 높음 | 없음 | ⭐⭐⭐ |

**Token Bucket**은 Stripe와 Amazon API Gateway가 사용하는 알고리즘으로, 버킷 용량만큼 순간적 버스트를 허용하면서도 평균 요청률을 제한합니다. 토큰이 일정 속도로 버킷에 채워지고, 요청마다 토큰을 소비하는 방식입니다. **Sliding Window Counter**는 Cloudflare가 채택한 방식으로, 이전 윈도우와 현재 윈도우의 가중 평균을 계산하여 Fixed Window의 경계 버스트 문제를 해결합니다. Cloudflare 데이터에 따르면 4억 건 요청 중 **0.003%만 오차**가 발생했습니다.

**Fixed Window의 치명적 단점**: 윈도우 경계에서 사용자가 제한의 2배를 요청할 수 있습니다. 예를 들어 100 req/min 제한에서 59초에 100건, 다음 윈도우 0초에 100건을 보내면 2초 만에 200건이 허용됩니다.

### 서버리스 환경 최적 선택: Sliding Window Counter

서버리스/엣지 환경의 핵심 제약은 **상태 비저장(stateless)**, **분산 실행**, **콜드 스타트**입니다. Sliding Window Counter가 최적인 이유:

- O(1) 메모리로 분산 상태 저장소에 적합
- 단일 원자적 연산(INCR)으로 Redis 왕복 최소화
- HTTP 기반 Redis 클라이언트(Upstash)와 완벽 호환
- 캐싱 친화적: 알려진 윈도우 경계로 로컬 캐싱 가능

---

## Next.js + Vercel 환경 구현 가이드

### Vercel 내장 Rate Limiting 기능

Vercel은 **WAF(Web Application Firewall)**를 통해 플랫폼 레벨의 Rate Limiting을 제공합니다. 모든 플랜에서 자동 DDoS 방어(L3/L4/L7)가 활성화되며, WAF 규칙은 전 세계 **300ms 내 전파**됩니다.

| 기능 | Hobby | Pro | Enterprise |
|-----|-------|-----|------------|
| 카운팅 키 | IP, JA4 Digest | IP, JA4 Digest | IP + 커스텀 헤더 |
| 알고리즘 | Fixed Window | Fixed Window | Fixed + Token Bucket |
| 시간 윈도우 | 10초-10분 | 10초-10분 | 10초-1시간 |
| 프로젝트당 규칙 | 1개 | 40개 | 1,000개 |

**중요**: Vercel KV는 2024년 말 **deprecated** 되었으며, Upstash로 마이그레이션되었습니다. 신규 프로젝트는 직접 Upstash를 사용해야 합니다.

### Edge Runtime 제약사항

Edge Runtime에서는 **Node.js 네이티브 API를 사용할 수 없습니다**. 전통적인 Redis 클라이언트(ioredis, node-redis)는 TCP 연결을 사용하므로 Edge에서 작동하지 않습니다. 반드시 **HTTP 기반 클라이언트**(@upstash/redis)를 사용해야 합니다.

```
❌ 사용 불가: ioredis, node-redis, require(), fs, crypto
✅ 사용 가능: @upstash/redis (REST API), fetch, Web APIs
```

**Next.js 15.5+/16 업데이트**: 이제 middleware에서 `runtime: 'nodejs'` 옵션으로 Node.js API를 사용할 수 있습니다. 단, 이 경우 Edge의 글로벌 분산 이점을 잃게 됩니다.

---

## Upstash Redis 구현 패턴

### 기본 설정 및 초기화

```typescript
// lib/ratelimit.ts
import { Ratelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";

// 핸들러 외부에서 선언하여 "hot" 함수에서 캐싱 이점 활용
const redis = Redis.fromEnv();

// 엔드포인트별 Rate Limiter 설정
export const rateLimiters = {
  // 일반 API (CRUD)
  general: new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(100, "1 m"),
    prefix: "@yiroom/ratelimit:general",
    ephemeralCache: new Map(), // 비용 절감용 로컬 캐시
    analytics: true,
  }),
  
  // AI 분석 엔드포인트
  aiAnalysis: new Ratelimit({
    redis,
    limiter: Ratelimit.tokenBucket(5, "1 m", 10), // 분당 5회, 최대 버스트 10회
    prefix: "@yiroom/ratelimit:ai",
    ephemeralCache: new Map(),
    analytics: true,
  }),
  
  // 인증 엔드포인트 (보안 강화)
  auth: new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(5, "15 m"), // 15분간 5회
    prefix: "@yiroom/ratelimit:auth",
    ephemeralCache: new Map(),
  }),
  
  // 파일 업로드
  upload: new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(10, "1 m"),
    prefix: "@yiroom/ratelimit:upload",
    ephemeralCache: new Map(),
  }),
};

// 사용자 티어별 Rate Limiter
export const tierLimiters = {
  free: new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(100, "1 h"),
    prefix: "@yiroom/ratelimit:free",
  }),
  premium: new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(1000, "1 h"),
    prefix: "@yiroom/ratelimit:premium",
  }),
};
```

### Next.js Middleware 통합

```typescript
// middleware.ts
import { NextFetchEvent, NextRequest, NextResponse } from "next/server";
import { rateLimiters } from "@/lib/ratelimit";

export async function middleware(
  request: NextRequest,
  context: NextFetchEvent
): Promise<NextResponse> {
  const pathname = request.nextUrl.pathname;
  const ip = request.ip ?? request.headers.get("x-forwarded-for") ?? "127.0.0.1";
  
  // 엔드포인트별 Rate Limiter 선택
  let limiter = rateLimiters.general;
  let identifier = ip;
  
  if (pathname.startsWith("/api/auth")) {
    limiter = rateLimiters.auth;
  } else if (pathname.startsWith("/api/ai") || pathname.startsWith("/api/analysis")) {
    limiter = rateLimiters.aiAnalysis;
    // AI 엔드포인트는 인증된 사용자 ID로 추적
    const userId = request.headers.get("x-user-id");
    identifier = userId || ip;
  } else if (pathname.startsWith("/api/upload")) {
    limiter = rateLimiters.upload;
  }
  
  const { success, limit, remaining, reset, pending } = await limiter.limit(identifier);
  
  // 비동기 작업(분석, 멀티리전 동기화) 완료 보장
  context.waitUntil(pending);
  
  // Rate Limit 초과 시
  if (!success) {
    const retryAfter = Math.ceil((reset - Date.now()) / 1000);
    
    return NextResponse.json(
      {
        type: "https://api.yiroom.com/errors/rate-limit",
        title: "요청 한도 초과",
        status: 429,
        detail: `요청 한도를 초과했습니다. ${retryAfter}초 후에 다시 시도해 주세요.`,
        retry_after: retryAfter,
      },
      {
        status: 429,
        headers: {
          "Retry-After": retryAfter.toString(),
          "X-RateLimit-Limit": limit.toString(),
          "X-RateLimit-Remaining": "0",
          "X-RateLimit-Reset": Math.ceil(reset / 1000).toString(),
        },
      }
    );
  }
  
  // 성공 시 헤더 추가
  const response = NextResponse.next();
  response.headers.set("X-RateLimit-Limit", limit.toString());
  response.headers.set("X-RateLimit-Remaining", remaining.toString());
  response.headers.set("X-RateLimit-Reset", Math.ceil(reset / 1000).toString());
  
  return response;
}

export const config = {
  matcher: ["/api/:path*"],
};
```

### 멀티리전 설정 (글로벌 사용자용)

```typescript
import { MultiRegionRatelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";

const globalRatelimit = new MultiRegionRatelimit({
  redis: [
    new Redis({ url: process.env.UPSTASH_REDIS_URL_US!, token: process.env.UPSTASH_REDIS_TOKEN_US! }),
    new Redis({ url: process.env.UPSTASH_REDIS_URL_EU!, token: process.env.UPSTASH_REDIS_TOKEN_EU! }),
  ],
  // 멀티리전에서는 Fixed Window 권장 (Sliding Window는 Redis 명령 증가)
  limiter: MultiRegionRatelimit.fixedWindow(100, "1 m"),
  analytics: true,
});
```

**비용 최적화 전략**: Upstash는 커맨드당 과금($0.20/100K)이므로 `ephemeralCache`를 반드시 활성화하여 DDoS 공격 시 반복 차단 요청의 Redis 호출을 방지합니다. Free 플랜으로 월 500K 커맨드까지 무료 사용 가능합니다.

---

## 엔드포인트별 임계값 권장사항

### 업계 표준 벤치마크

주요 API 서비스들의 Rate Limiting 정책을 분석한 결과입니다:

| 서비스 | 읽기 작업 | 쓰기 작업 | AI/이미지 |
|-------|----------|----------|----------|
| **GitHub** | 5,000/시간 (인증) | 쓰기 간 1초 대기 권장 | - |
| **Stripe** | 100/초 | 25/초 | - |
| **OpenAI** | Tier 1: 500 RPM | - | 30,000-200,000 TPM |
| **Anthropic** | Tier 1: 50 RPM | - | 30,000 input TPM |
| **DALL-E 3** | - | - | 15-60 이미지/분 |

### Yiroom 권장 임계값

**퍼스널 컬러 분석 및 AI 추천 서비스** 특성을 고려한 권장값입니다:

| 엔드포인트 타입 | Free 티어 | Premium 티어 | 근거 |
|---------------|----------|--------------|------|
| **일반 API (GET)** | 100/분, 1,000/시간 | 500/분, 10,000/시간 | 읽기는 리소스 부담 적음 |
| **일반 API (POST/PUT)** | 20/분, 200/시간 | 100/분, 1,000/시간 | DB 쓰기 비용 고려 |
| **AI 이미지 분석** | **10회/일** | 100/시간 | GPU 비용 ($0.02-0.05/회 추정) |
| **퍼스널 컬러 분석** | **5회/일** | 50/일 | 고비용 AI 처리 |
| **패션/뷰티 추천** | 20/분 | 100/분 | 텍스트 AI 기반 |
| **로그인** | 5회/15분 | 5회/15분 | 보안상 동일 적용 |
| **회원가입** | 3회/시간 (IP당) | - | 어뷰징 방지 |
| **파일 업로드** | 10/분, 최대 10MB | 30/분, 최대 100MB | 스토리지/대역폭 비용 |
| **동시 요청** | 5개 | 20개 | 긴 처리시간 보호 |

**AI 엔드포인트 특별 고려사항**: 이미지 처리는 텍스트 처리 대비 **10-15배** 더 많은 컴퓨팅 자원을 소비합니다. 퍼스널 컬러 분석처럼 복잡한 이미지 AI는 일 단위 제한과 함께 **큐 기반 비동기 처리**를 권장합니다.

---

## 사용자 피드백 UX 패턴

### HTTP 응답 헤더 표준

**IETF 표준**(draft-ietf-httpapi-ratelimit-headers)과 **레거시 X-RateLimit** 헤더를 함께 제공하여 호환성을 확보합니다:

```typescript
// 응답 헤더 예시
{
  // 레거시 (널리 사용됨)
  "X-RateLimit-Limit": "100",
  "X-RateLimit-Remaining": "0", 
  "X-RateLimit-Reset": "1706779260",  // Unix timestamp (초)
  
  // IETF 신규 표준
  "RateLimit-Policy": '"default";q=100;w=60',
  "RateLimit": '"default";r=0;t=45',
  
  // 필수
  "Retry-After": "45"  // 초 단위 권장 (타임존 이슈 방지)
}
```

**중요**: `X-RateLimit-Reset` 값은 Unix timestamp(초)가 아닌 **남은 초(seconds)** 형식이 클라이언트 구현에 더 안전합니다. 시계 동기화 문제를 피할 수 있습니다.

### 한국어 에러 메시지 템플릿

```typescript
// lib/rateLimit/messages.ts
export const rateLimitMessages = {
  // 기본 에러
  exceeded: {
    title: "요청 한도 초과",
    message: (retryAfter: number) => 
      `요청 횟수가 한도를 초과했습니다. ${retryAfter}초 후에 다시 시도해 주세요.`,
  },
  
  // 경고 (한도 임박)
  warning: {
    title: "요청 한도 임박",
    message: (remaining: number, resetIn: number) =>
      `남은 요청 횟수: ${remaining}회 (${resetIn}초 후 초기화)`,
  },
  
  // AI 분석 전용
  aiLimited: {
    title: "AI 분석 한도 초과",
    message: "오늘의 무료 AI 분석 횟수를 모두 사용했습니다.",
    upgrade: "프리미엄으로 업그레이드하면 더 많은 분석을 이용할 수 있어요!",
    queue: "대기열에 등록되었습니다. 처리 완료 시 알림을 보내드릴게요.",
  },
  
  // 인증 관련
  authLimited: {
    title: "로그인 시도 제한",
    message: "보안을 위해 로그인 시도가 일시적으로 제한되었습니다.",
    help: "비밀번호를 잊으셨다면 비밀번호 재설정을 이용해 주세요.",
  },
};
```

### React 프론트엔드 구현

```typescript
// hooks/useRateLimit.ts
import { useCallback, useState } from 'react';
import { toast } from 'sonner'; // 또는 shadcn/ui toast

interface RateLimitStatus {
  remaining: number | null;
  limit: number | null;
  resetIn: number | null;
  isNearLimit: boolean;
}

export function useRateLimit() {
  const [status, setStatus] = useState<RateLimitStatus>({
    remaining: null,
    limit: null,
    resetIn: null,
    isNearLimit: false,
  });

  const updateFromHeaders = useCallback((headers: Headers) => {
    const remaining = parseInt(headers.get('x-ratelimit-remaining') || '');
    const limit = parseInt(headers.get('x-ratelimit-limit') || '');
    const reset = parseInt(headers.get('x-ratelimit-reset') || '');
    
    if (!isNaN(remaining) && !isNaN(limit)) {
      const resetIn = Math.max(0, reset - Math.floor(Date.now() / 1000));
      const isNearLimit = remaining < limit * 0.1; // 10% 미만
      
      setStatus({ remaining, limit, resetIn, isNearLimit });
      
      // 한도 임박 시 사전 경고
      if (isNearLimit && remaining > 0) {
        toast.warning('요청 한도 임박', {
          description: `남은 요청 횟수: ${remaining}회`,
        });
      }
    }
  }, []);

  const handleRateLimitError = useCallback((response: Response) => {
    const retryAfter = parseInt(response.headers.get('retry-after') || '60');
    
    toast.error('요청 한도 초과', {
      description: `${retryAfter}초 후에 다시 시도해 주세요.`,
      duration: Infinity, // 자동 닫힘 방지
      action: {
        label: '재시도',
        onClick: () => window.location.reload(),
      },
    });
    
    return retryAfter;
  }, []);

  return { status, updateFromHeaders, handleRateLimitError };
}
```

### Axios 인터셉터 패턴

```typescript
// lib/api.ts
import axios from 'axios';

const api = axios.create({ baseURL: '/api' });

// 지수 백오프 + 지터
async function exponentialBackoff<T>(
  fn: () => Promise<T>,
  maxRetries = 3
): Promise<T> {
  let delay = 1000;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error: any) {
      if (error.response?.status === 429 && attempt < maxRetries) {
        const retryAfter = parseInt(error.response.headers['retry-after']) || 0;
        const waitTime = retryAfter * 1000 || delay;
        const jitter = Math.random() * 1000; // Thundering herd 방지
        
        await new Promise(r => setTimeout(r, waitTime + jitter));
        delay *= 2;
        continue;
      }
      throw error;
    }
  }
  throw new Error('Max retries exceeded');
}

api.interceptors.response.use(
  (response) => {
    // 모든 응답에서 Rate Limit 헤더 추적
    const event = new CustomEvent('ratelimit-update', {
      detail: {
        remaining: response.headers['x-ratelimit-remaining'],
        limit: response.headers['x-ratelimit-limit'],
        reset: response.headers['x-ratelimit-reset'],
      },
    });
    window.dispatchEvent(event);
    return response;
  },
  async (error) => {
    if (error.response?.status === 429) {
      // 자동 재시도 옵션
      if (error.config._autoRetry !== false) {
        return exponentialBackoff(() => api.request(error.config));
      }
    }
    throw error;
  }
);

export { api };
```

### AI 엔드포인트용 큐 기반 처리

퍼스널 컬러 분석처럼 처리 시간이 긴 AI 작업은 **Server-Sent Events(SSE)**를 활용한 비동기 처리를 권장합니다:

```typescript
// app/api/ai/analyze/route.ts
import { rateLimiters } from '@/lib/ratelimit';

export async function POST(request: Request) {
  const userId = request.headers.get('x-user-id')!;
  
  // Rate Limit 체크
  const { success } = await rateLimiters.aiAnalysis.limit(userId);
  
  if (!success) {
    // 큐에 등록하고 나중에 처리
    const jobId = await queueAnalysisJob(userId, await request.json());
    
    return Response.json({
      status: 'queued',
      job_id: jobId,
      message: '대기열에 등록되었습니다. 처리 완료 시 알림을 보내드립니다.',
      estimated_wait: '약 5분',
    }, { status: 202 }); // 202 Accepted
  }
  
  // 즉시 처리
  const result = await processAnalysis(await request.json());
  return Response.json(result);
}

// 클라이언트: SSE로 진행 상황 구독
// components/AnalysisProgress.tsx
function AnalysisProgress({ jobId }: { jobId: string }) {
  const [progress, setProgress] = useState(0);
  
  useEffect(() => {
    const eventSource = new EventSource(`/api/ai/status?job_id=${jobId}`);
    
    eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'progress') {
        setProgress(data.percentage);
      } else if (data.type === 'complete') {
        setProgress(100);
        eventSource.close();
        // 결과 페이지로 이동
      }
    };
    
    return () => eventSource.close();
  }, [jobId]);
  
  return (
    <div className="analysis-progress">
      <p>퍼스널 컬러 분석 중... {progress}%</p>
      <ProgressBar value={progress} />
    </div>
  );
}
```

### Toast vs Modal 사용 가이드

| 상황 | UI 컴포넌트 | 이유 |
|-----|-----------|-----|
| 한도 임박 경고 (10% 미만) | Toast | 비차단, 정보성 |
| 한도 초과 (첫 번째) | Toast + 액션 버튼 | 닫기 가능, 재시도 유도 |
| 일일 AI 분석 한도 초과 | Modal | 중요 결정(업그레이드) 필요 |
| 보안 잠금 (로그인 실패) | Modal | 반드시 인지 필요 |
| 백그라운드 재시도 성공 | Toast | 간단한 확인 |

---

## 구현 체크리스트

### 백엔드 설정
- [ ] Upstash Redis 계정 생성 및 환경변수 설정 (`UPSTASH_REDIS_REST_URL`, `UPSTASH_REDIS_REST_TOKEN`)
- [ ] @upstash/ratelimit, @upstash/redis 패키지 설치
- [ ] 엔드포인트별 Rate Limiter 인스턴스 생성 (핸들러 외부)
- [ ] `ephemeralCache` 활성화로 비용 최적화
- [ ] middleware.ts에 Rate Limiting 로직 통합
- [ ] 인증 엔드포인트에 강화된 제한 적용 (5회/15분)
- [ ] AI 엔드포인트에 일일 제한 + 큐 시스템 구현
- [ ] 사용자 티어별 차등 제한 구현 (free/premium prefix 분리)

### HTTP 응답 설정
- [ ] 429 상태 코드 + RFC 9457 Problem Details JSON 반환
- [ ] `Retry-After` 헤더 포함 (초 단위)
- [ ] `X-RateLimit-Limit`, `X-RateLimit-Remaining`, `X-RateLimit-Reset` 헤더 포함
- [ ] 성공 응답에도 Rate Limit 헤더 포함 (사전 경고용)

### 프론트엔드 구현
- [ ] Axios 인터셉터로 Rate Limit 헤더 자동 추적
- [ ] 지수 백오프 + 지터 재시도 로직 구현
- [ ] 한도 임박 시 Toast 경고 표시
- [ ] 한도 초과 시 한국어 에러 메시지 표시
- [ ] AI 분석 큐 등록 시 진행 상황 UI (SSE)
- [ ] 프리미엄 업그레이드 유도 Modal

### 모니터링 및 운영
- [ ] Upstash 분석 대시보드 활성화 (`analytics: true`)
- [ ] `context.waitUntil(pending)` 호출로 비동기 작업 완료 보장
- [ ] 어뷰징 패턴 모니터링 및 IP 차단 규칙 설정
- [ ] Vercel WAF 규칙으로 1차 방어선 구축

---

## 참고 자료 및 출처

### 공식 문서
- Upstash Rate Limiting 문서: https://upstash.com/docs/redis/sdks/ratelimit-ts/overview
- Vercel WAF 문서: https://vercel.com/docs/security/firewall
- Next.js Middleware 문서: https://nextjs.org/docs/app/building-your-application/routing/middleware

### RFC 및 표준
- RFC 6585: HTTP 429 Too Many Requests (https://tools.ietf.org/html/rfc6585)
- IETF Draft: RateLimit Header Fields (draft-ietf-httpapi-ratelimit-headers)
- RFC 9457: Problem Details for HTTP APIs

### 기술 블로그 및 사례 연구
- Cloudflare Engineering: "How we built rate limiting capable of scaling to millions of domains"
- Stripe Engineering: Token Bucket 기반 4-tier rate limiting 아키텍처
- Kong: Enterprise API Gateway Rate Limiting 설계

---

## 결론

Yiroom 서비스에서는 **Upstash Redis + Sliding Window Counter**를 기본 알고리즘으로 채택하고, AI 이미지 분석 엔드포인트에는 **Token Bucket + 큐 기반 비동기 처리**를 적용하는 하이브리드 전략을 권장합니다. 무료 사용자의 AI 분석은 일 **5-10회**로 제한하되, 큐 시스템을 통해 "대기 후 처리" 옵션을 제공하여 사용자 경험과 인프라 비용의 균형을 맞출 수 있습니다. 프론트엔드에서는 Rate Limit 헤더를 사전에 추적하여 한도 초과 전에 사용자에게 경고를 제공하고, 초과 시에는 명확한 한국어 메시지와 재시도 타이밍을 안내하는 것이 핵심입니다.